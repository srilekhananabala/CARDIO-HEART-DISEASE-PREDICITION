{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "metadata": {
        "id": "_4-v7bZ0xyct"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the data\n",
        "df = pd.read_csv('/content/framingham.csv')"
      ],
      "metadata": {
        "id": "wXgFHafhx5_x"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the rows with missing values for simplicity\n",
        "df = df.dropna()\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = df.drop('TenYearCHD', axis=1)\n",
        "y = df['TenYearCHD']"
      ],
      "metadata": {
        "id": "kMZWaxydyHo-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting  the data into training set  and testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features by scaling them\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "-5J87byFyjBx"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Random Forest classifier\n",
        "random_forest = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define the grid of hyperparameters to search\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [5, 10, 15],  # Reducing the maximum depth of the trees\n",
        "    'min_samples_split': [5, 10, 15],  # Increasing the minimum number of samples required to split a node\n",
        "    'min_samples_leaf': [1, 2, 4]  # Increasing the minimum number of samples required to be at a leaf node\n",
        "}\n"
      ],
      "metadata": {
        "id": "-LC2cEZbywin"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get the best parameters and the best score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Accuracy Score:\", best_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QnmkApsy4NS",
        "outputId": "d97ba095-b3cc-4ce5-eb62-1ba89abc0b71"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100}\n",
            "Best Accuracy Score: 0.8526997462151046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the best model for prediction\n",
        "best_random_forest = grid_search.best_estimator_\n",
        "y_pred = best_random_forest.predict(X_test_scaled)\n",
        "\n",
        "# Calculate accuracy on testing data\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYTK_Kyzy_1a",
        "outputId": "30563c3a-e14b-4ac9-b1e4-b28c93e9100e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracy: 0.8346994535519126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #Fit the model to the training data\n",
        "best_random_forest.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions on training data\n",
        "y_train_pred = best_random_forest.predict(X_train_scaled)\n",
        "\n",
        "# Calculate accuracy on training data\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "\n",
        "print(\"Training Accuracy:\", train_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5DXrgMUzE7r",
        "outputId": "eda4382a-54c3-4f88-971d-71c340739e43"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.8735475051264525\n"
          ]
        }
      ]
    }
  ]
}